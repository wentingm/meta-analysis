"PICO","Paper","SimilarityScore"
"Intelligent Tutoring Systems, post-test or exam results, K-12 students","A very big adventure: using the internet to enable multi-institutional collaboration in teaching computer ethics. Teaching and learning in any subject can sometimes become mundane but in order that our students are motivated it is sometimes necessary to use an approach which makes the process a very big adventure. Over the past three years studies have taken place with students from the University of Limerick in Ireland and students from two other universities in England and the USA in the teaching of Professional Issues in Software Engineering PISE (Griffin, 2001, Griffin et al 2000a and 2000b). PISE focuses on the legal, ethical and social aspects of computing. The ethical strand of this module, which aims to develop moral reasoning in the learners, has in the author's experience often proved to be the most difficult for students to grasp and consequently has had a de-motivating effect on some learners. To deal with this situation the author decided to investigate methods by which students might be motivated and therefore gain more from their learning experiences and develop their moral reasoning abilities. The method adopted has been the use of virtual learning groups using internet based asynchronous communication tools to enable learners who would otherwise physically be unable to meet to come together in cyberspace and discuss moral issues relating to computer systems. This paper describes two cycles of the study, the results obtained, lessons learned and a proposal for a multi-cultural approach to be used in future studies. Analysis of the development of moral reasoning by preand post testing students using Moral Judgment Test (MJT) (Lind, 2001) is provided. The results of this research will be of value for both academic and practitioners in the area of computer ethics and moral reasoning. Introduction Over the past three years the author has been evaluating a multi-institutional approach to teaching and assessing students on courses that deal with computer ethics (Griffin, 2001, Griffin et al 2000a and Griffin et al 2000b). In these studies, students from the University of Limerick in Ireland (UL), de Montfort University in England (DMU) and Sacred Heart University in the USA (SHU) who were following similar courses, worked together in virtual learning groups to solve moral dilemmas. Groups were established with students from each institution represented in roughly equal numbers. Each group selected a scenario from a list supplied by the course tutors and worked over a six week period using asynchronous communication tools provided by the Blackboard system (see below). On completion of this assessment task groups were independently graded according to an agreed grading scheme by course tutors form the three participating institutions. The Moral Judgment Test (Lind, 1986) was also used to assess what if any changes may have occurred in students’ moral reasoning while working in multiinstitutional virtual groups. Analysis examined the changes in the MJT C-index (Lind 2002 and see below) from the pre course stage to post course stage. Reasons for the changes in this score have been used to suggest alterations to the design of collaborative teaching in this academic field. In the first field study there was no significant difference in the C-index scores of learners in multi-institutional groups compared with those in control groups from a single institution. In a follow up study differences were noted. It is now proposed to expand the range of learners and institutions involved to include faculty and students from non-Western cultural and ethical traditions in future cycles of this work.","1"
"Intelligent Tutoring Systems, post-test or exam results, K-12 students","Work in Progress: Intelligent Tutoring Systems in Computer Science and Software Engineering Education. Many research reports have been published over the last 30 years on the use of intelligent tutoring systems in computer science and software engineering education, but no previous systematic review has been conducted to describe and assess the field as a whole. This project (in progress) searched for publications meeting defined inclusion criteria and identified 280 eligible reports. We are currently coding these works using 28 variables that will allow us to describe the research field in aggregate. The results will tell us: What research questions are being asked? What are the types of student modeling being used? What subject domains have ITS been designed for? What issues or themes are most evident in recent research? What are the gaps in research on intelligent tutoring systems in computer science and software engineering education. Finally, what technological and pedagogical innovations are needed to advance research in this field? Research on intelligent tutoring systems (ITS) has accelerated over the last decade, and scholarly interest in such systems has never been greater. 1 ITS have been developed for a wide range of subject domains (e.g., mathematics, physics, biology, medicine, reading, languages, and philosophy) and for students in primary, secondary and postsecondary levels of education. Although most ITS have been developed by researchers and never deployed outside the laboratory or the single university-level course for which they were designed, there are examples of mature systems that have been deployed more widely and extensively evaluated. 2, 3 Like previous reviewers 1, 4, 5 we have adopted a definition of ITS that emphasizes student modeling as an essential characteristic. We identify an ITS as any computer system that performs teaching or tutoring functions (e.g., selecting assignments, asking questions, giving hints, evaluating responses, providing feedback, prompting reflection, providing comments that boost student interest) and adapts or personalizes those functions by modeling students’ cognitive, motivational or emotional states. This definition distinguishes ITS from test-and-branch tutorial systems which individualize instruction by matching a student’s most recent response against preprogrammed, question-specific targets. Complicating matters, there are sophisticated P ge 26754.2 computerized adaptive testing systems, not usually considered to be ITS, that use item response theory to model student ability as a single dimension. 6 To distinguish ITS from such systems we further specify that student modeling must be multidimensional. Quantitative and Meta-Analytic Reviews on the Effectiveness of ITS The first quantitative review which compared the instructional effectiveness of ITS to other types of instruction was an analysis published in 2011 by VanLehn that examined learning outcomes in STEM. 7 VanLehn was primarily interested in distinguishing between human tutoring and three types of computer-based tutoring systems: answer-based, step-based, and substep-based. Answer-based systems typically assign a problem and then provide feedback and further branching that depends on the student’s answer. Conventional test-and-branch, computer-based instruction programs are usually classified as answer-based systems. Step-based and substepbased systems have finer-grained interfaces that provide instructional support as the student progresses through the solution of a problem. Most ITS that teach students procedures for solving problems in areas such as math, physics and chemistry would be classified as step-based or substep-based systems. VanLehn found very little difference in post-test performance between students learning from human tutoring and step-based or substep-based systems; and, based on a small number of primary studies, he found that answer-based systems tend to produce poorer posttest performance than step-based systems (.40 SD) and substep-based systems (.32 SD). Steenbergen-Hu and Cooper published two methodologically rigorous meta-analyses on the effects of using ITS. 8, 9 In a 2013 review covering primary and secondary mathematics they found no significant difference between ITS and other modes of instruction when measured by standardized tests; but when measured by course-specific tests designed by teachers or researchers, there was a small, statistically significant effect (g = .19) favoring ITS. In 2014, they published a second meta-analysis that examined ITS learning outcomes in postsecondary education. They found that, overall, ITS significantly outperformed other modes of instruction (g = .35). They also found that human tutoring produced only slightly better results than ITS (g = -.25), and the difference was not statistically significant. More recently, we co-authored the first comprehensive meta-analysis on the effectiveness of ITS. 1 It included all available studies prior to 2012 that compared ITS to other types of instruction. We analyzed 107 effect sizes comparing learning outcomes from ITS against other types of instruction and found a statistically significant, overall weighted mean effect size favoring ITS of approximately g = .40. Similar effect sizes were found when ITS were compared specifically to textbooks, large teacher-led classes, and non-ITS computer-based instruction. However, no significant differences in learning outcomes were found when ITS were compared to one-to-one tutoring and small group instruction. ITS were found to be significantly more effective than other types of instruction at all levels of schooling (elementary, secondary, and postsecondary) and in most subject domains, including computer science (approximately, g = .50). To summarize, the recent quantitative reviews indicate that research has found ITS to be more effective than other types of instruction except one-to-one and small group instruction provided P ge 26754.3 by a human. For unknown reasons, this pattern of advantage for ITS was not found in the specific case of mathematics at the elementary and secondary levels. Meta-Analysis of ITS in Computer Science and Software Engineering Education We recently reported a meta-analysis of 22 effect sizes that compared ITS to other types of instruction in the subject domain of computer science and software engineering (CS/SE) education. 10 Although an overall effect size associated with ITS in the domain had been already established 1 our meta-analysis sought to examine how the effect of using ITS breaks out by moderator variables such as type of student modeling and whether the ITS modeled misconceptions. The studies that met our inclusion criteria were published from 1998 to 2013. Although a few of the better-known student modeling techniques were represented in our sample, most of the ITS tested in the primary research used ‘one-off’ student model designs that appeared in only a single evaluative study. We found that learning outcomes were significantly higher for students using ITS than those learning in large teacher-led classes (g = .67) or from non-ITS, computer-based instruction (g = .89). ITS were associated with better learning outcomes when they were used as the principle means of instruction and also when they served an assistive or supplementary function. ITS were more effective than other types of instruction when they modeled misconceptions (g = .41) and when they did not (g = .68). Purpose of the Systematic Review Meta-analysis is appropriate for assessing an intervention that is identifiable prior to the searching and coding stages of the review process. Because meta-analysis focuses on comparison of pre-identified treatments it is not suitable for a broader examination of the whole body of research on a topic such as the use of ITS in CS/SE education. As it required quite specific inclusion criteria, our meta-analysis excluded all but 21 research publications, which we observed to be a minor fraction of all research on the topic. We are now conducting a systematic review to discover the significant features of research in the field. The review is addressing questions such as:  What subject areas within CS/SE education (e.g., programming, database design) have been taught by ITS?  What instructional functions (e.g., task assignment and sequencing, hints, feedback, motivational prompts) are adapted by the systems?  What types of student models are being designed and used?  What instructional strategies are the ITS based on?  What interface features are being used in the ITS? P ge 26754.4  What research questions are being investigated?  What are the most recent research trends?  In what ways might the research be advanced or improved? The systematic review is critically evaluating research on the use of ITS in software engineering education and will make recommendations for improving the quality of methods and reporting in primary studies.","0"
"Intelligent Tutoring Systems, post-test or exam results, K-12 students","Learning, Adaptive Support, Student Traits, and Engagement in Scenario-Based Learning. Scenario-based training systems pose an especially difficult challenge for an intelligent tutoring system (ITS). In addition to the basic problems of deciding when to intervene and what guidance to provide, the ITS must decide whether to give guidance directly (e.g., a hint message), indirectly through positive/negative results in the scenario, or to delay guidance until a post-scenario review session. There are a number of factors that an adaptive ITS should consider and we use self-report survey instruments to investigate the relationship between traits, learning strategies, expectations, learner behaviors derived from log files, post-use perceptions of the system, and pre-test and post-test results. We use the ELITE Lite Counseling training system as a testbed for our experiments. This system uses virtual role players to allow learners to practice leadership counseling skills, and is in use at the United States Military Academy (USMA). This paper analyzes two data sets. We collected data from local university students, a nonmilitary population of roughly the same age as USMA Cadets using the system. For these local participants, we could administer surveys and pre-tests and post-tests, and collect log files recording clicks made while using ELITE Lite. The second data set comes from USMA itself but is limited to log files. In both populations, the ITS’s hints are effective at boosting scenario performance, and for the university students, the overall experience promoted learning, and survey results suggest that higher levels of organization in study habits may lead to greater learning with ELITE Lite. For the USMA Cadets, ELITE Lite is part of their Military Leadership course rather than an experiment, which could explain why we found higher scenario performance on average than the non-military population, and more use of the post-scenario review feature.","0"
"Intelligent Tutoring Systems, post-test or exam results, K-12 students","Early Intervention for At-Risk Online Students. then described a study in which students were tested in three categories: online treatment, online control, and face-to-face control. They measured levels of interest using the Course Interest Survey, which is based on the ARCS model. Students in the treatment group received mass emails every two weeks, composed based on the ARCS model to attract attention and convey personal interest in learner success; to remind of student personal control and reinforce confidence and satisfaction by giving students knowledge of what was expected of them. They also included words of support and encouragement, and points of contact for instructor availability. The results from the study showed a lot of improvement from the control and treatment groups, and demonstrated similar results between the face-to-face group and treatment group. (4), 285-298. This article outlines a plan of student online learning retention and intervention for students who are struggling or at-risk. The optional, student initiated support plan, called ‘SOS’, involves five-steps that help students receive scaffolding instruction, learning support and academic coaching to help in times of stress or when problems or issues arise. The steps are to first ask/request to receive the introductory guide and scaffolding, second, answer an SOS planning questionnaire (for helping identify specific issues and problems to be addressed), third, receive academic coaching/scaffolding and individual feedback, fourth, receive an SOS map and mp3 that will help map out success, and fifth, SOS Scaffolding/coaching sessions in the discussion area of the course. The program was optional for students, but the students that went through the program reported great success in engaging and benefitting from community building, individualized education plans, organization skills, study skills, tech skills, and group This article focused primarily on a test done by researchers on the effects of motivational treatments on students and their learning behaviors. The study was mainly geared towards students who were struggling in school because of low optimism or lack of motivation. The study has not been done on students of online learning, but the results found from the focus groups that were tested showed that the motivational treatments helped improve overall class test results, and the students that were part of the goal engagement treatment program outperformed their no-treatment peers by 7-8%. The treatments given were in an online format, and showed significant improvement for students with co-occurring risk factors. 1-19. doi:10.1037/mot0000107 The advantages and disadvantages of using Open Educational Resources in online student learning are analyzed and explained in this article. OER are defined as technology enabled open provision of educational resources for consultation, use, and adaptation by a community of users for non-commercial purposes. (IE lessons, modules, full courses/programs, guides, e-texts, articles, audio tracks, videos, multimedia, or other learning materials) Researchers performed a study at a University level to determine whether using OER as a part of Online Courses significantly helped students improve in their courses. Results showed that even with the limitations of OER, the positive impact it has on students’ learning is significant, especially as far as Interventions and classes were studied, half were randomly assigned to receive interventions of emails sent on behalf of the faculty that included online and in-person resources that could help them improve their course performance. The data collected from the students included “triggers” based on use reports that were significantly related to student final grade. Other interventions that were suggested included supplemental instruction, one-on-one tutoring sessions, or directed study resources. The interventions were shown to significantly improve student final grade. doi:  10.1145/2723576.2723657 This article analyzed the implementation and effects of Attributional Retraining Treatments to help foster engagement and motivation to improve the retention rates of struggling students. A study is presented that focuses on the hypothesis that students’ performances have more to do with psychosocial variables and the nature of learning experiences than academic successes previously experienced. The AR treatments include causal attributions, shifting/changing students perceived control, and motivation treatments. The study concluded that the implementation of these treatments contributed widely to student retention and success as they continued http://jolt.merlot.org/vol8no1/ryabov_0312.htm This article focuses on aiding students in online courses by of collaboration, conversations and interactions the teacher and online support personal. There are five basic approaches to supporting students: one-on-one consultation (clinical model) through an “open-door” policy; separate accredited subjects within existing courses; parallel classes; generic support and teaching and learning partnerships that embed the student learning support into This articulated specific and direct ways that at-risk students were being identified and ways to target interventions toward their specific needs based on various research conducted. Researchers were identified as using a range of computational techniques to predict learning progression (ie Bayesian modeling, cluster analysis, natural language processing, machine learning, predictive modeling and social media analysis). The article stated that while many researchers and institutions are experimenting with small-scale targeted interventions, there is no comprehensive conceptual model, with a strong evidence base that describe how teachers and administrators can use learning analytics to make successful interventions in their own practice. Different techniques such as monitoring VLE data (number of clicks, number of messages posted in a discussion forum, number of computer formative assessments attempted) supplemented by individual learner characteristics (prior educational attainment, socio-economic data, or were shown not to be as effective for identifying at-risk students as other, more in depth analytics, such as researching learners’ activities during continuous assessments over time. The Open University Analytics study used predictive models constructed by machine learning methods from legacy data recorded in the previous presentation of the same module and performance of learners predicted weekly from the predictive models and the learner data of the current presentation to make their predictions. The article went over different methods and protocol to helping students who are at risk as well. Before the start of the course, a learner will be assessed on their strengths and weaknesses in 4 categories, cognitive, social, teaching, and emotional, and specific guidelines are given to support the student throughout the course relevant to the category he or she struggled the most in. (2), 51-56. This article analyzes the pilot residential learning community project at Indiana University Southeast, which targets first-generation students who are academically at-risk. The study tracks the students’ progress and performance to see if they improve in a number of aspects such as student engagement, academic performance, and second-year retention/credit-hour completion. According to the study, research shows that one of the main reasons students are at-risk of dropping out is because they feel like they don’t belong. The RLC works to connect students with each other so that they have a stronger support system that can help in both retention and interventions. To measure the effectiveness of the RLC, surveys were created and given to the students to measure student engagement, data was gathered on retention and credit hour completion, and assessment tools were created to measure in students are sure to succeed. article used collected from different using this redesign method and six characteristics make in article surrounding individual characteristics of students. A study was performed in which students from a large state university were analyzed and the results showed that prior performance in college (cumulative GPA), and class-standing (senior vs non- senior) were significant characteristics related to student retention in online classes. Other factors significantly related include previous withdrawal from online courses, gender, and recipient of academic loans. Demographic variables such as gender, age, and race are potential explanatory variables to the variance in higher education. The article explains and analyzes these factors in relation to the retention of students in online learning courses. 27-48. doi:10.1007/s11162-013-9305-8. This article clearly articulated the uses and structure of different data collection/learning analytics that have been and are being used to help identify at-risk students. According to the article, big data (datasets whose size is beyond the ability of a typical database software tools to capture, store, manage, and analyze) is a lot more productive in the context of helping improve student learning and retentions than other ways of collecting data. Analytics in learning should be cycled through these 5 steps, as proposed by the researchers writing this article: Course level(Learning trails, social network analysis, discourse analysis), Educational data-mining (predictive modeling, clustering, pattern mining) Intelligent curriculum (the development of semantically defined curricular resources), Adaptive content (adaptive sequence of content based on learner behavior, recommender systems) and Adaptive Learning (the adaptive learning process-social interactions, learning activity, learner support, not only content). The article then goes on to describe LMSs and VLEs and their functions and flaws. The article suggests that new ways of using technol","0"
"Intelligent Tutoring Systems, post-test or exam results, K-12 students","Development of an Intelligent Tutoring System Using Bayesian Networks and Fuzzy Logic for a Higher Student Academic Performance. In this experimental study, an intelligent tutoring system called the fuzzy Bayesian intelligent tutoring system (FB-ITS), is developed by using artificial intelligence methods based on fuzzy logic and the Bayesian network technique to adaptively support students in learning environments. The effectiveness of the FB-ITS was evaluated by comparing it with two other versions of an Intelligent Tutoring System (ITS), fuzzy ITS and Bayesian ITS, separately. Moreover, it was evaluated by comparing it with an existing traditional e-learning system. In order to evaluate whether the academic performance of the students in different learning groups differs or not, analysis of covariance (ANCOVA) was used based on the students’ pre-test and post-test scores. The study was conducted with 120 undergraduate university students. Results showed that students who studied using FB-ITS had significantly higher academic performance on average compared to other students who studied with the other systems. Regarding the time taken to perform the post-test, the results indicated that students who used the FB-ITS needed less time on average compared to students who used the traditional e-learning system. From the results, it could be concluded that the new system contributed in terms of the speed of performing the final exam and high academic success.","1"